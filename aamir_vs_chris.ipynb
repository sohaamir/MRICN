{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNcVbeW67wBtsuMWHZjCJFA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sohaamir/aamir_vs_chris/blob/main/aamir_vs_chris.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Who has the bigger brain, me or Chris Gorgolewski? A gentle introduction to nipype**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oJ9w_yscJn_F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is Google Colab?\n",
        "**Google Colaboratory** is is a free cloud-based platform provided by Google that offers a Jupyter notebook environment for writing and executing Python code. It is primarily used for data analysis tasks but can also be used for general-purpose Python programming. It has many benefits when working with data (including neuroimaging data) such as:\n",
        "\n",
        "1.   Free access\n",
        "2.   Cloud-based hosting (available everywhere)\n",
        "3.   GPU/TPU Support (lots of processing power)\n",
        "4.   External Data Access (import data GitHub, Google Drive, local machine)\n",
        "\n",
        "It is an interactive environment similar to Anaconda, but with certain advantages (like those mentioned above). Similarly, Colab allows for users to run code in small chunks called 'cells', displaying any output such as images directly within the notebook as well. The programming language used by these notebooks is `Python`, which it organises in the form of `Jupyter Notebooks`."
      ],
      "metadata": {
        "id": "21WlPOaDTV7Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What can we do in Google Colab?\n",
        "\n",
        "We can do a whole bunch of things..."
      ],
      "metadata": {
        "id": "rDOLRjkGR3ch"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### We can use it for data visualization and plotting"
      ],
      "metadata": {
        "id": "KsOpCKUYXW0N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "x = np.linspace(0, 10, 100)\n",
        "y = np.sin(x)\n",
        "\n",
        "plt.plot(x, y)\n",
        "plt.title(\"Sine Wave\")\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"sin(X)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sLBCH2zBXeNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def mandelbrot(c, max_iter):\n",
        "    z = 0\n",
        "    n = 0\n",
        "    while abs(z) <= 2 and n < max_iter:\n",
        "        z = z*z + c\n",
        "        n += 1\n",
        "    return n\n",
        "\n",
        "def mandelbrot_image(xmin, xmax, ymin, ymax, width=10, height=10, max_iter=256):\n",
        "    # Create a width x height grid of complex numbers\n",
        "    x = np.linspace(xmin, xmax, width * 100)\n",
        "    y = np.linspace(ymin, ymax, height * 100)\n",
        "    X, Y = np.meshgrid(x, y)\n",
        "    C = X + 1j * Y\n",
        "\n",
        "    # Compute Mandelbrot set\n",
        "    img = np.zeros(C.shape, dtype=int)\n",
        "    for i in range(width * 100):\n",
        "        for j in range(height * 100):\n",
        "            img[j, i] = mandelbrot(C[j, i], max_iter)\n",
        "\n",
        "    # Plotting\n",
        "    plt.figure(figsize=(width, height))\n",
        "    plt.imshow(img, extent=(xmin, xmax, ymin, ymax), cmap='hot')\n",
        "    plt.colorbar()\n",
        "    plt.title(\"Mandelbrot Set\")\n",
        "    plt.show()\n",
        "\n",
        "# Parameters defining the extent of the region in the complex plane we're going to plot\n",
        "xmin, xmax, ymin, ymax = -2.0, 0.5, -1.25, 1.25\n",
        "width, height = 10, 10\n",
        "max_iter = 256\n",
        "\n",
        "mandelbrot_image(xmin, xmax, ymin, ymax, width, height, max_iter)"
      ],
      "metadata": {
        "id": "6txgqlC7bUs8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Watch YouTube"
      ],
      "metadata": {
        "id": "Vo2qyNzbXtk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import YouTubeVideo\n",
        "\n",
        "# Embedding the YouTube video\n",
        "YouTubeVideo('GtL1huin9EE', width=800, height=450)"
      ],
      "metadata": {
        "id": "5BoCUY2bXxo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Learning about neuroimaging"
      ],
      "metadata": {
        "id": "X6gFinutYyMX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is nipype?\n",
        "nipype, to quote the website aims to \"provide an environment that encourages interactive exploration of algorithms from different packages (e.g., ANTS, SPM, **FSL**, FreeSurfer, Camino, MRtrix, MNE, AFNI, Slicer, DIPY), eases the design of workflows within and between packages, and reduces the learning curve necessary to use different packages.\"\n",
        "\n",
        "To quote [Nick Hedger](https://github.com/N-HEDGER/):\n",
        "\n",
        "> **The simplest way of thinking about nipype is as an interface (or set of interfaces) that allow all of our favourite neuroimaging packages to talk to one another and work effectively together.**\n"
      ],
      "metadata": {
        "id": "YGOKCc7hRz-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "Image(url='https://www.researchgate.net/publication/349017135/figure/fig1/AS:987364692328449@1612417495314/Neuroimaging-analysis-pipeline-A-An-automated-NIPYPE-pipeline-extracted-structural-and.jpg')"
      ],
      "metadata": {
        "id": "3nfd4A0iP5Wm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eAI5gApbGpG0"
      },
      "outputs": [],
      "source": [
        "# Step 1: Install necessary packages\n",
        "!pip install nibabel nipype matplotlib\n",
        "!pip install imageio\n",
        "\n",
        "# Step 2: Download the MRI scan files from GitHub\n",
        "!wget https://github.com/sohaamir/aamir_vs_chris/raw/main/sub-CG_T1w.nii -O sub-CG_T1w.nii\n",
        "!wget https://github.com/sohaamir/aamir_vs_chris/raw/main/sub-0002_ses-1_acq-mprage_rec-NORM_T1w.nii -O sub-0002_ses-1_acq-mprage_rec-NORM_T1w.nii\n",
        "\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from nipype.interfaces import fsl\n",
        "import imageio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load and visualize the MRI scans\n",
        "def visualize_mri(path, slice_index):\n",
        "    # Load the image\n",
        "    img = nib.load(path)\n",
        "    data = img.get_fdata()\n",
        "\n",
        "    # Plot the image\n",
        "    plt.imshow(data[:, :, slice_index], cmap='gray')\n",
        "    plt.show()\n",
        "\n",
        "    return img"
      ],
      "metadata": {
        "id": "MrL9TqcJKNwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize a slice of the first MRI\n",
        "img1 = visualize_mri('sub-CG_T1w.nii', slice_index=100)\n",
        "\n",
        "# Visualize a slice of the second MRI\n",
        "img2 = visualize_mri('sub-0002_ses-1_acq-mprage_rec-NORM_T1w.nii', slice_index=100)"
      ],
      "metadata": {
        "id": "FylzHFusJ6tx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to normalize and create a GIF from a 3D MRI scan in the sagittal plane\n",
        "def create_gif_from_mri_normalized(path, gif_name):\n",
        "    # Load the image and get the data\n",
        "    img = nib.load(path)\n",
        "    data = img.get_fdata()\n",
        "\n",
        "    # Normalize the data for better visualization\n",
        "    # Clip the top and bottom 1% of pixel intensities\n",
        "    p2, p98 = np.percentile(data, (2, 98))\n",
        "    data = np.clip(data, p2, p98)\n",
        "    data = (data - np.min(data)) / (np.max(data) - np.min(data))\n",
        "\n",
        "    # Prepare to capture the slices\n",
        "    slices = []\n",
        "    # Sagittal slices are along the x-axis, hence data[x, :, :]\n",
        "    for i in range(data.shape[0]):\n",
        "        slice = data[i, :, :]\n",
        "        slice = np.rot90(slice)  # Rotate or flip the slice if necessary\n",
        "        slices.append((slice * 255).astype(np.uint8))  # Convert to uint8 for GIF\n",
        "\n",
        "    # Create a GIF\n",
        "    imageio.mimsave(gif_name, slices, duration=0.1)  # duration controls the speed of the GIF"
      ],
      "metadata": {
        "id": "EN-TWTPBK6F7"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "# Create and display the GIF for the first MRI\n",
        "create_gif_from_mri_normalized('sub-CG_T1w.nii', 'brain1_normalized.gif')\n",
        "display(Image(filename='brain1_normalized.gif'))"
      ],
      "metadata": {
        "id": "C9ujVibpLVOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and display the GIF for the second MRI\n",
        "create_gif_from_mri_normalized('sub-0002_ses-1_acq-mprage_rec-NORM_T1w.nii', 'brain2_normalized.gif')\n",
        "display(Image(filename='brain2_normalized.gif'))"
      ],
      "metadata": {
        "id": "jCY7VDjjPN-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Calculate the size of the brains\n",
        "# Here we'll just count the non-zero voxels as a proxy for brain size\n",
        "# This is a naive approach; in practice you would want a more sophisticated method\n",
        "size_img1 = np.count_nonzero(img1.get_fdata())\n",
        "size_img2 = np.count_nonzero(img2.get_fdata())\n",
        "\n",
        "print(f\"Size of brain in the first image: {size_img1} voxels\")\n",
        "print(f\"Size of brain in the second image: {size_img2} voxels\")\n",
        "\n",
        "# Compare sizes\n",
        "if size_img1 > size_img2:\n",
        "    print(\"The first brain is larger.\")\n",
        "elif size_img1 < size_img2:\n",
        "    print(\"The second brain is larger.\")\n",
        "else:\n",
        "    print(\"The brains are the same size.\")"
      ],
      "metadata": {
        "id": "JBiPzlAOKFXC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}